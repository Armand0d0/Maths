
\documentclass[letterpaper,10pt]{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{stmaryrd}
%\usepackage{graphicx}

\usepackage{biblatex} %Imports biblatex package
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\addbibresource{bibliography.bib} %Import the bibliography file


\title{Exos sympas}
\author{Armand Perrin}

\begin{document}

\maketitle%---------------------------------------------------------------
\newcommand{\m}[1]{\ensuremath{\mathbb{#1}}}
\newcommand{\tx}[1]{\ensuremath{\mathrm{#1}}}

\newcommand{\mn}[1]{\ensuremath{\mathcal{M}_n(\mathbb{#1})}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}
\newcommand{\car}[1]{\ensuremath{\chi_{_{#1}}}}
\newcommand{\n}[1]{\ensuremath{\|#1\|}}
\newcommand{\gln}[1]{\ensuremath{GL_n(\mathbb{#1})}}
\setlength\parindent{0pt}
\newcommand{\exercice}[3]{
  \fbox{%
\begin{minipage}{1.0\textwidth}
  \paragraph{Exercice #1:} #2

\end{minipage}
}
  \paragraph{Solution :} #3 $ \\ \\ \\$
}%-------------------------------------------------------------------------------------
Voici une séléction d'exercices sympatiques rencontrés lors de ma prépa en MPI* au lycée Paul Valery. Je les ai séléctionné essentiellement selon le
 plaisir que j'ai eu à les chercher ainsi que l'élégance de leurs solutions. On y trouvera notament des exercices type oral ENS dont la difficulté rend le fait 
 de trouver une solution plus satifaisant encore, ce qui joue indéniablement un rôle dans ma séléction. Lors de la rédaction des solutions (qui est encore en cours), je
  m'efforce de décrire non seulement la preuve mais aussi le cheminement pour y parvenir. En esperant éviter cet effet "bouquin" de rédaction minimale où l'on ne donne 
  que la synthèse et cache l'analyse qui pourtant est aussi instructive. Par ailleurs ma rédaction est loin d'être parfaite, merci de me faire part de toute erreur, 
  coquille ou suggestion.\\ \\ \\% \begin{center}***\end{center} \\
\exercice{1}{
Soit $(G,.)$ un groupe fini dont tous les éléments sont d'ordre 2, montrer que son
cardinal est une puissance de 2.}
{On propose 2 solution, la première très astucieuse et jolie et la deuxième plus accessible et généralisable.
\paragraph{Solution 1:}
Cette solution consiste à remarquer que $(G,\cdot,\wedge)$ est un $\Z/2\Z$-espace vectoriel (ça a un sens car $\Z/2\Z$ est un corps).\\
Où la loi externe $\wedge$ est définie par 
$ \wedge: \left\{ \begin{array}{rcl} \Z/2\Z\times G& \longrightarrow & G \\
   (n,x) & \longmapsto & x^n \\ \end{array} \right. $
 En effet : \\ - $ (G,.)$ est un groupe abélien : 
Soient $x,y \in G\quad  1 = (xy)^2 = xyxy $ et en composant a gauche par 
$x$ et a droite par $y$ on a bien $xy = yx$.\\
- $\forall x\in G \quad x^1 = x$\\
- $\forall x,y \in G, n\in \Z/2\Z \quad (xy)^n = x^ny^n$ car $G$ est abélien.\\
- $\forall n,m \in \Z/2\Z, x\in G \quad x^{n+m} = x^nx^m$\\
- $\forall n,m \in \Z/2\Z, x\in G \quad (x^n)^m = x^{nm}$\\
cet espace vectoriel est de dimension finie  car il est fini ( tout famille de taille supérieure à $card(G)$ est liée). Notons $k$ sa dimension, la fixation d'une base de $G$ induit un isomorphisme entre $G$ et $(\Z/2\Z)^k$ ils sont donc de même cardinal :  $2^k$.
\setlength\parindent{0pt}
\paragraph{Solution 2:}
On démontre par récurrence sur $k$ la propriété : ``pour tout groupe $G$ dont tous les éléments sont d'ordre 2 : $card(G) \leq 2^k \implies \exists p \in \mathbb{N}$ tel que $card(G) = 2^p$ ''. Avoir cette propriété pour tout $k$ permet clairement de conclure. \\
Initialisation :  si $k = 0$ c'est bon.\\
Hérédité : supposons la propriété réalisée pour $k \geq 1$, soit $G$
un groupe dont tous les éléments sont d'ordre 2 tel 
que $card(G) \leq 2^{k+1}$ , si $card(G) \leq 2^k$ c'est bon par 
l'hypothèse, sinon soit $H$ un sous groupe strict de $G$ de cardinal 
maximal (existe car ils sont en nombre fini) et $a \in G\setminus H$ 
alors $G = H \cup aH$ et $H\cap aH=\emptyset$, en effet $H\cup aH$ est 
un sous groupe de $G$ :
\par\leftskip 10pt
-$ 1 \in H\cup aH$\\
-Soient $x,y \in H\cup aH$
\par\leftskip 20pt
si $x,y \in H$ alors $xy^{-1} \in H \subset H\cup aH$\\si $x,y\in aH\quad \exists h,h'\in H \quad xy^{-1} = ah(ah')^{-1} = hh'^{-1} \in H$ car $G$ est commutatif (voir Solution 1)\\ si $x\in H,y\in aH$ (ou le contraire, par symétrie) $\exists h,h'\in H \quad xy^{-1} = h(ah')^{-1} = ahh'^{-1} \in aH$ car $a^{-1} =a$.\par
\leftskip 0pt
Alors $H\cup aH = G$ par maximalité de $H$. Soit $x\in H \cap aH \quad \exists h,h' \in H \quad h' = ah$ absurde car alors $a= h'h^{-1} \in H$. Ainsi $H\cap aH=\emptyset$. En vertue de la bijection $x \mapsto ax,\quad card(H) =card(aH)$. On déduit de ces 3 points que $card(G) = 2card(H)$, donc $card(H) \leq 2^k$ et par l'hypothèse de récurrence $\exists p \in \mathbb{N} \quad card(H) = 2^p$ puis $card(G) = 2^{p+1}$.
}
\exercice{2 (d'après \cite{igor})}%---------------------------------------------------------------
{
  Soit $\mathbb{K}$ un corps et $A_1, \ldots,A_p$ un ensemble de $p$ matrices de $GL_n(\mathbb{K})$ stable
par produit, montrer que \[\ \tx{Tr}\Biggl(\sum_{i=1}^p A_i\Biggr) \equiv 0\left[p\right] \]
}
{
  Notons $G$ cet ensemble et $S = \sum_{i=1}^pA_i$, il faut remarquer que si $j \in \llbracket 1 , p \rrbracket$ 
\[\ \sum_{i=1}^pA_jA_i = \sum_{i=1}^pA_i = S \text{ car } M \mapsto A_jM \text{ est une permutation de } G \] \[\ \text{Alors, }
S^2 = \Biggl(\sum_{i=1}^pA_i\Biggr)^2 =  \sum_{i=1}^p\sum_{j=1}^pA_iA_j = p\sum_{i=1}^pA_i = pS
\] Si la caractéristique de $\m{K}$ divise $p$ (c'est à dire si $p.1_{\m{K}} = 0_{\m{K}}$) alors $S^2=0$, $S$ est donc nilpotente et sa trace est nulle.
On a bien $\tx{Tr}(S) \equiv 0 \left[p\right] $.   \[\ \text{Sinon : }\Bigl(\frac{S}{p}\Bigr)^2 = \frac{pS}{p^2} = \frac{S}{p} \] $\frac{S}{p}$ est donc un projecteur,  sa trace est donc égale à son rang, c'est donc un entier et par linéarité, la trace de S est divisible par $p$. 

}

\exercice{3}{
Soient $a,b\in \mathbb{R},\;\; a<b$ et $f:\left[a,b\right] \to \mathbb{R}$ continue 
sur $\left[a,b\right]$, dérivable sur $\left]a,b\right[$ nulle en $a$ et $b$.
 Soit $\lambda \in \mathbb{R}$.
Démontrer que $f' + \lambda f$ s'annule sur $\left]a,b\right[$. 

}{

Les hypothèses ressemblent à celles du théorème de Rolle, on va chercher à l' appliquer, mais à quelle fonction ? \\
Analyse : On va chercher par exemple $g$ dérivable vérifiant \\
- $g(a) = g(b)$\\
- $g'(c) = 0 \implies f'(c) + \lambda
f(c) = 0$\\
le deuxième point serait vérifié si par exemple $g'= (f'+\lambda f)h$ avec $h$ une fonction strictement positive. Choisissons $h$ de manière à pouvoir primitiver $g'$ on remarque que $g'$ est la dérivée du produit $fh$ si $h' =\lambda h$ ce qui fonctionne avec $h : x\mapsto e^{\lambda x}$.\\
Synthèse : On applique le théorème de Rolle à $g:x\mapsto f(x)e^{\lambda x}, g $ est continue sur $\left]a,b\right[$, dérivable sur $\left[a,b\right]$, nulle en $a$ et $b$ donc $ \exists c \in \left]a,b\right[ \quad g'(c) = 0 $ or $g'(x) = (f'(x) + \lambda f(x))e^{\lambda x}$ donc $f'(c) + \lambda f(c) = 0$. 
}
\exercice{4}{
    Retrouver le binome de Newton à l'aide de la formule de Leibniz.
}{
    Si $a\in \mathbb{C}$ on cherche une fonction $f$ de classe $\mathcal{C}^{\infty}$ pour laquelle on ait une relation simple entre $f^{(k)}$ et $a^k$ pour tout $k$. Dans la lignée de l'exercice précédant on va considerer les fonctions exponentielles, posons : $f_a : x \mapsto e^{ax}$ alors $f_a^{(k)} = a^kf_a$.
    Soient $a,b \in \mathbb{C},n\in \mathbb{N}$ on a avec Leibniz : \[\
    (a+b)^n = (a+b)^ne^{(a+b)\times 0} =f_{a+b}^{(n)}(0) = (f_af_b)^{(n)}(0)\] \[\ = \sum_{k=0}^n\binom{n}{k}f_a^{(k)}(0)f_b^{(n-k)}(0) = \sum_{k=0}^n \binom{n}{k}a^kb^{n-k}
    \]
}
\exercice{5 (Bézout dans \mn{Z})}{
Soient $A,B \in \mn{Z}$ telles que $ det(A) \wedge det(B) = 1$, montrer qu'il
existe $U,V \in \mn{Z}$ telles que : \[\ AU+BV = I_n\]
}
{
C'est direct quand on pense à la formule $MCom(M)^{T}= det(M)I_n$,
car une relation de Bézout dans $\mathbb{Z}$ permet d'écrire : \[\ 
\exists u,v \in \mathbb{Z} \quad ACom(A)^{T}u + BCom(B)^Tv = (det(A)u+det(B)v)I_n = I_n
\]
}
\exercice{6}{
Soit $M \in \mn{C}$, démontrer que $M$ est diagonalisable si et seulement si
sa classe de simlitude est fermée.
}{
  $\boxed{\Rightarrow }$ Supposons $M$ diagonalisable,\\ on note $C = \{PMP^{-1} , P \in GL_n(\mathbb{C}) \}$ la classe de similitude de $M$, démontrons qu'elle est fermée. Soit $(M_n)_n \in C^{\mathbb{N}}$ convergente de limite $L \in \mn{C}$.
Notons $\Pi_M$ le polynome minimal de $M$ et $\chi_{_M}$ son polynome caractéristique. L'applcation $M \mapsto det(XI_n -M) = \chi_{_M}$ étant continue car polynomiale, on a $\chi_{_{M_n}} \rightarrow \chi_{_L}$ or $\forall n \in \mathbb{N} \quad \chi_{_{M_n}} = \chi_{_M}$ donc $\chi_{_M} = \chi_{_L}$. De plus, on a classiquement pour $P \in GL_n(\mathbb{C}) \quad \Pi_M(PMP^{-1}) =  P\Pi_M(M)P^{-1} = 0$. Donc $\forall n\in \mathbb{N} \quad \Pi_M(M_n) = 0$ et par continuitée de $\Pi_M : \mn{C} \to \mn{C}$ comme polynome, $\Pi_M(L) = 0$ or $\Pi_M$ est scindé, à racines simples puisque $M$ est diagonalisable, donc $L$ est aussi diagonalisable. $M$ et $L$ ont le même polynome caractéristique et sont diagonalisables donc semblables a une même matrice diagonale, elles sont donc semblables entre elles et $L \in C$.\\
$\boxed{\Leftarrow}$ Supposons que la classe de similitude $C$ de $M$ est fermée. On veut démontrer que $M$ est diagonalisable, ce qui équivaut à dire que $C$ contient une matrice diagonale. Il suffit donc de trouver une suite d'éléments de $C$ convergeant vers une matrice diagonale, puisque $C$ est fermée. $M$ est trigonalisable dans $\mathbb{C}$ donc on peut trouver $T \in C$ triangulaire supérieure. Considérons pour $k \in \mathbb{N}^*$ la matrice digonale inversible : $P_k = \left( \begin{matrix}k & 0 & \ldots & 0 \\ 0 & k^2  & \ldots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0& \ldots & k^n \end{matrix}\right)$ d'inverse $\left( \begin{matrix}\frac{1}{k} & 0 & \ldots & 0 \\ 0 & \frac{1}{k^2}  & \ldots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0& \ldots & \frac{1}{k^n} \end{matrix}\right)$. La suite $(U_k)_k= (P_kTP_k^{-1})_k$ de $C$ converge vers $diag(t_{1,1},\ldots,t_{n,n})$ où $T =(t_{i,j})_{1\leq i,j \leq n}$. En effet le coefficient d'indice $(i,j)$ de $U_k$ vaut $t_{i,j}k^{i-j}$. Si $i>j$ alors $t_{i,j} =0$, si $i<j\quad k^{i-j} \to 0$ et si $i=j\quad t_{i,j}k^{i-j} \to t_{i,i}.\;\;_{_\square}$
\paragraph{Remarque : } On peut démontrer avec la même méthode que $M$ est nilpotente si et seulement si $0 \in \overline{C}$ (l'adhérence de $C$).
}
\exercice{7 (Théorème de Maschke)}{
Soit $E$ un espace vectoriel de dimension finie et G un sous groupe fini de 
$GL(E)$. Démontrer que tout sous espace vectoriel de $E$ stable par tous les éléments de $G$ admet un 
supplémentaire également stable par tout les élément de $G$.
}{
  Disons d'un sous-espace qu'il est stable par $G$ si il est stable par tous les éléments de $G$.
Soit $F$ un sous-espace vectoriel de $E$ stable par $G$. On va travailler avec des projecteurs, il est bien de se rendre compte que à un couple de sous espaces supplémentaire on peut toujours faire correspondre un projecteur et vice versa car le noyeau et l'image d'un projecteur sont supplémentaires. Soit donc $p$ un projecteur sur $F$. L'idée principale pour construire un supplémentaire stable par $G$ est de chercher à construire un projecteur à partir de $p$ et $G$ ayant aussi $F$ pour image et dont le noyeau est stable par $G$.
On a déja remarqué dans l'exercice 2 que la somme des éléments d'un sous groupe fini de $GL_n(\mathbb{K})$ divisée par son cardinal est un projecteur, on peut donc s'en inspirer et poser $s = \frac{1}{n} \sum_{g \in G} gpg^{-1}$, où $n= card(G)$,
de cette manière : \[\ s^2 = \frac{1}{n^2} \sum_{g \in G}\sum_{h \in G} hph^{-1}gpg^{-1} = \frac{1}{n}\sum_{g \in G}gpg^{-1} =s \] car $p_{|F} =id_F$ et $F =Im(p)$ est stable par $G$. $s$ est le projecteur recherché, on a $Im(s) = F$ en effet :\\ $\boxed{\subset}$ Cette incluson est claire pusique $F$ est stable par $G$.\\ $\boxed{\supset}$ si $x\in F$  alors $ x = p(x) = \frac{1}{n}\sum_{g \in G} gpg^{-1}(x) \in Im(s)$ car $p_{|F} =id_F$.\\
On a aussi $Ker(s)$ stable par $G$ : soit $x\in Ker(s)$, et $h \in G$ \\
\[\ s(h(x)) = \frac{1}{n} \sum_{g\in G} gpg^{-1}(h(x)) = \frac{1}{n} \sum_{g\in G} hh^{-1}gp(h^{-1}g)^{-1}(x) = hs(x) = 0\] car $g \mapsto h^{-1}g$ est une permutation de $G$. Donc $Ker(s)$ est stable par $G$. Finalement comme $ Ker(s) \oplus F = Ker(s) \oplus Im(s) = E,\;\; Ker(s)$ est le supplémentaire recherché.\\ 
\\ $Remarque :$ Cette preuve est vraie pour tout corps $\mathbb{K}$ tel que $n.1_{\mathbb{K}}\neq 0$ (pour pouvoir diviser par $n$), c'est à dire dont la caractéristique ne divise pas $n$.\\
\paragraph{Autre solution si $\mathbb{K} =\mathbb{R}$ :} On identifie $E$ et $\mathbb{R}^p$ que l'on munit du produit scalaire canonique $<.,.>$, et on pose le produit scalaire $(.|.)$ sur $E$ définit par : \[\ \forall x,y \in E \quad (x|y) = \sum_{g\in G} <g(x),g(y)> 
\] On travaille dans l'espace euclidien $(E,(.|.)) $, encore par la bijection $g\mapsto hg$ pour $h \in G$, on constate que tout les éléments de $G$ conservent le produit scalaire, donc sont autoadjoints et donc $F^{\perp}$ est un supplémentaire de $F$ stable par $G$.
}
\exercice{8}{ Démontrer que $GL_n(\mathbb{C})$ est connexe par
 arcs.
}{ Soit $A \in GL_n(\mathbb{C})$
On va exhiber une application continue $\phi : \left[ 0,1 \right] \to GL_n(\mathbb{C})$ telle que $\phi(0) = I_n$ et $\phi(1) = A$ 

Regardons pour commencer le chemin en ligne droite : $\psi_A(t) = tA + (1-t)I_n$ il n'a pas de raison de rester dans $GL_n(\mathbb{C})$ mais pour \[\ t \in \left] 0,1\right] \quad \psi_A(t) \in GL_n(\mathbb{C})\quad \Leftrightarrow \quad A + \frac{1-t}{t}I_n \in GL_n(\mathbb{C}) \Leftrightarrow \frac{1-t}{t} \notin Sp(A) \] Il suffit donc que $A$ n'ait aucune valeur propre réelle pour que ce chemin $\psi_A$ soit à valeurs dans $GL_n(\mathbb{C})$. Que faire si ce n'est pas le cas ? Trouver un chemin continu de $A$ à une matrice dont les valeurs propres ne sont pas réelles. Posons \[\  
r:\left\{ \begin{matrix}
 \left[0,1\right] &
  \longrightarrow & GL_n(\mathbb{C}) \\  t & \longmapsto &  e^{2i\pi t}A \end{matrix} \right. \] 
Si $Sp(A) = \{\lambda_1,\ldots,\lambda_n \}$ alors $Sp(r(t)) = \{e^{2i\pi t}\lambda_1,\ldots,e^{2i\pi t}\lambda_n\}$.\\ Puisque   l'ensemble $\{ t\in \left[ 0,1\right] | \exists k \in \llbracket 1,n \rrbracket \quad e^{2i\pi t}\lambda_k \in \mathbb{R}\}$ 
est fini on peut trouver  $t_0\in \left[0,1\right]$ 
tel que $Sp(r(t_0)) \subset \mathbb{C}\setminus \mathbb{R}$. Notons $B = r(t_0) $. La restriction de $r$ à $ \left[0,t_0\right]$ est donc un chemin continu à valeurs dans $GL_n(\mathbb{C})$ joignant $A$ et $B$, de même $\psi_B$ continu à valeurs dans $GL_n(\mathbb{C})$ joint $B$ et $I_n$, on construit donc facilement $\phi $ comme il faut.}
%------------------------------------------------------------------------------------------------------------------------------------------------

\exercice{9 (ENS Lyon 2014)}{

Determiner une CNS sur $A$ et $B$ dans $\mn{C}$ pour que \[\
\forall k \in \mathbb{N} \quad tr(A^k) = tr(B^k) \quad (*) \]
}
{
Pour commencer simplifions le problème et cherchons les matrices $A$ qui vérifient \[\
\forall k \in \mathbb{N^*}\quad tr(A^k) = 0
\quad (**) \] C'est classique, on commence par observer que toutes les matrices 
nilpotentes fonctionnent, puis on montre que ce sont les seules :
 démontrons que si $A \in \mn{C}) $ verifie $(**)$ alors son
  spectre est réduit à \{0\}. Notons $ \lambda_1,..., \lambda_r$ les valeurs propres non nulles de $A$ où les $\lambda_i$ sont distinct 2 à 2, $n_i \geq 1$ la multiplicité de $\lambda_i$ et $n_0 \geq 0$ la multiplicité de 0. On raisonne par l'absurde en supposant $r \geq 1$,
$(**)$ pour $k\in \llbracket 0, r \rrbracket $ donne : 
\begin{alignat*}{6}
n_0 + &n_1\lambda_1^0 &+\ldots &+n_r\lambda_r^0 & = n\\
&n_1\lambda_1 &+\ldots&+n_r\lambda_r  &= 0\\
&n_1\lambda_1^2 &+\ldots&+n_r\lambda_r^2 &= 0 \\
&\vdots &\vdots  & & \vdots \\
&n_1\lambda_1^{r} &+\ldots&+n_r\lambda_r^{r} &= 0
\end{alignat*}
Donc 
\[\ \begin{pmatrix}
1 & 1 &\ldots & 1 \\
0^1 & \lambda_1^1 & \ldots & \lambda_r^1 \\
\vdots & \vdots & \vdots & \vdots \\
0^r & \lambda_1^r & \ldots & \lambda_r^r \\
\end{pmatrix}\begin{pmatrix}n_0-n \\ n_1\\ \vdots \\ n_r
\end{pmatrix}
=\begin{pmatrix}0 \\ 0\\ \vdots \\ 0
\end{pmatrix}\]
Il s'agit d'un système type Vandermonde  inversible,
on en déduit $\forall i \in\llbracket 1, r\rrbracket \;\; n_i = 0 $ ce qui est absurde, donc $r = 0$ et $Sp(A) =$ \{0\}

Pour le cas général ont peut remarquer que si $A$ et $B$ ont le même polynome
 caractéristique alors elles vérifient $(*)$ de plus la réciproque est vraie 
 si $B=0$ d'après ce qui précède. On va montrer qu'elle est toujours vraie. 
 Pour une matrice $M$ notons $\chi_{_M}$ son polynome caractéristique et $\Pi{_M}$ 
 son polynome minimal. Fixons $A$ et $B$ dans $\mn{C})$ vérifiant $(*) $.
  D'abord, la linéarité de la trace permet d'écrire : \[\ \forall P \in 
  \mathbb{C}\left[X\right] \quad tr(P(A)) = tr(P(B)) \] 
Soit $k \in \mathbb{N}^*$ pour  $P = \chi_{_B}^k$ on a donc 
d'après Cayley-Hamilton : \[\ tr(\chi_{_B}^k(A)) = 0 \] La matrice
 $\chi_{_B}(A)$ est donc nilpotente, donc $\chi_{_B}^n$ annule $A$, donc
  $\Pi_{A} | \chi_{_B}^n$ et donc $Sp(A) \subset Sp(B)$. Par symétrie on 
  obtient ensuite l'inclusion réciproque, donc $Sp(A) = Sp(B)$.

Il ne reste plus qu'a montrer que les multiplicités des valeurs propres sont les
 mêmes pour avoir $\chi_{_A} =\chi_{_B}$. Notons $\{\lambda_1,\ldots,\lambda_r\}$ 
 le spectre commun et $a_i, b_i$ la multiplicité de $\lambda_i$ dans $\chi_{_A}$ 
 et $\chi_{_B}$ respectivement. $(*)$ donne alors :
\begin{alignat*}{8}
 &a_1\lambda_1^0 &+ \ldots  +& a_r\lambda_r^0 &=&\; b_1\lambda_1^0 &+ \ldots  +& b_r\lambda_r^0 \\
&\vdots & & & \vdots & & \vdots &\\
 &a_1\lambda_1^{r-1} &+ \ldots  +& a_r\lambda_r^{r-1} &=&\; b_1\lambda_1^{r-1} &+ \ldots  +& b_r\lambda_r^{r-1} \\
\end{alignat*} Ce qui s'écrit :
\[\ \begin{pmatrix}
1  &\ldots & 1 \\
\lambda_1^1 & \ldots & \lambda_r^1 \\
\vdots & \vdots & \vdots \\
\lambda_1^{r-1} & \ldots & \lambda_r^{r-1} \\
\end{pmatrix}\begin{pmatrix}a_1-b_1 \\ a_2-b_2\\ \vdots \\ a_r-b_r
\end{pmatrix}
=\begin{pmatrix}0 \\ 0\\ \vdots \\ 0
\end{pmatrix}\] On retombe sur une matrice de Vandermonde inversible et on conclut que \[\ \forall i \in \llbracket 1,r \rrbracket \quad a_i= b_i \] ce qui conclut.
}
%------------------------------------------------------------------------------------------------------------------------------------------------

\exercice{10 (Cassini)}{Soit $g\in \mathcal{C}^0(\left[ a, b\right],\mathbb{R})$. On pose $f_0 = g$ et \[\ \forall n \in \mathbb{N} \quad f_{n+1} = \int_af_n \] Étudier la convergence de la série de fonctions : \[\ \sum_{n\geq 0}f_n \] et calculer sa somme.

}{
%solution_____
Remarquons que $\forall n \in \mathbb{N} \quad f_n$ est de classe $ \mathcal{C}^n$ et $f_n^{(k)}  = f_{n-k}$ et si $n \neq 0$ $ f_n(a)=0$.
$g$ est bornée sur le segment $\left[ a,b\right]$ car elle y est continue notons $M$ une borne de $g$. Soit $x\in \left[ a,b\right]$ le théorème de Taylor-Lagrange appliqué à $f_n$ entre $a$ et $x$ s'écrit :
\[\ \Bigg|f_n(x)-\sum_{k=0}^{n-1}\frac{f_n^{(k)}(a)}{k!}(x-a)^k\Bigg|\leq \frac{M(x-a)^n}{n!} \]\[\ |f_n(x)|\leq \frac{M(b-a)^n}{n!}\] Par passage au $sup$
 on déduit que la série de terme général $\|f_n\|_{\infty} $ converge. Donc $\sum_{n\geq 0}f_n$ converge normalement donc uniformément sur $ \left[ a,b\right]$.\\
Calculons maintenant sa somme, que l'on note $s$ :\\
Soit $x \in \left[ a,b\right]$ : 
\[\ \int_a^xs(t)dt = \int_a^x\sum_{n=0}^{\infty}f_n(t)dt\]

La convergence uniforme nous autorise ici à échanger série et intégrale :

\begin{align*} \int_a^xs(t)dt &=  \sum_{n=0}^{\infty}\int_a^xf_n(t)dt \\ &= \sum_{n= 0}^{\infty}f_{n+1}(x) \\ &= s(x) -g(x) \\ \text{Notons } S(x) &= \int_a^xs(t)dt. \end{align*}

Alors $S' - S = g$, équation différentielle facile à résoudre, on obtient avec la condition $S(a) =0$ que  : \[\ S(x) = e^{x}\int_a^xg(t)e^{-t}dt \] et 
\[\ s(x) = g(x) + e^{x}\int_a^xg(t)e^{-t}dt  \]}
%------------------------------------------------------------------------------------------------------------------------------------------------

\exercice{11}{
Soit $A\subset \mathbb{C}$, exhiber un $\mathbb{K}$-espace vectoriel pour  $\mathbb{K} = \mathbb{R}$ ou $\mathbb{C}$ et $f\in L(E)$ tel que $Sp(f) = A$.
% Create a new 1st level heading
}{
Considérons $E = \mathcal{C}^{\infty}(\mathbb{R},\mathbb{C})$ et $D:f\mapsto f'$ l'endomorphisme de dérivation sur $E$, puis pour
 $\lambda \in \mathbb{C}\quad f_{\lambda}:x\mapsto e^{\lambda x}$.\\On pose $F = Vect_{\mathbb{C}}\Big((f_{\lambda})_{\lambda \in A}\Big)= 
 Vect_{\mathbb{R}}\Big((f_{\lambda})_{\lambda \in A}, (if_{\lambda})_{\lambda \in A} \Big)$ qui est dans tous les cas un sous espace vectoriel de $E$ vu comme $\mathbb{K}$-espace vectoriel, la suite de la preuve est similaire  que $\mathbb{K}$ soit $ \mathbb{R}$ ou $\mathbb{C}$ : \\

On constate que $F$ est stable par $D$, notons $d = D_{|F} \in L(F)$ : \[\ \forall \lambda \in A\quad d(f_{\lambda}) = \lambda f_{\lambda}\]
Et comme les $f_{\lambda}$ sont tous non nuls, $A \subset Sp(d)$.
Soit maintenant $\lambda \in Sp(d)$, \[\ \exists f \in F \quad f' = \lambda f \] On peut résoudre cette équation différentielle, 
et on obtient \[\ \exists K \in \mathbb{C}\quad \forall x \in \mathbb{R}\quad f(x) = Ke^{\lambda x} \] On a aussi $f \in F$, et la famille 
$(f_{\lambda})_{\lambda \in \mathbb{C}}$ est $\mathbb{K}$-libre, donc nécessairement $f = Kf_{\lambda}$ avec $\lambda \in A$. Ainsi $A = Sp(d)$.
}
\exercice{12 (Théorème de Burnside)}{
  On dit qu'un groupe $G$ est d'exposant fini si : \[\ \exists N \in \m{N}^* \quad \forall g \in G  \quad g^N = 1\] Le plus petit entier $N$   vérifiant cela est alors appelé l'exposant de $G$, c'est aussi le plus petit multiple commun des ordres des éléments de $G$.\\ \\ Démontrer qu'un sous groupe de $GL_n(\m{C})$ est d'exposant fini si et seulement si il est fini.
}{
  Il est clair que si $G$ est fini $\forall g \in G \quad g^{|G|} =1$ donc $G$ est d'exposant fini. 
  Réciproquement supposons $G$ d'exposant fini, on va montrer que $G$ est fini en construisant une injection de $G$ dans un ensemble fini. Soit $B = (B_1,\ldots,B_r)$ une famille libre de $G$ de cardinal maximal, on vérifie facilement que c'est une base de $Vect(G)$.\\
  Posons $ f: \left\{ \begin{array}{rcl} Vect(G) & \longrightarrow & \m{C}^r \\ A & \longmapsto & (Tr(AB_1),\ldots,Tr(AB_r)) \\ \end{array} \right. 
  $ $f$ est linéaire, montrons que $f_{|G}$ est injective: On vérifie facilement qu'il suffit pour ça de montrer que $Ker(f)\cap G =\{0\}$.  Soit $A \in Ker(f)\cap G$ et $k \in \m{N}$, on peut decomposer $A^k$ dans la base $B$, notons : \[\ A^k = \sum_{i=1}^r a_iB_i \] \[\ Tr(A^{k+1}) = \sum_{i=1}^r a_iTr(AB_i) = 0 \] Car $A \in Ker(f)$ donc \[\ \forall k \in \m{N}^*\quad Tr(A^k) = 0 \]
  Cela implique que $A$ est nilpotente (exercice classique, voir exo 9). Or le ploynome scindé à racines simples $X^N-1$ annule $A$ puisque $A \in G$, donc $A$ est diagonalisable et nilpotente, elle est donc nulle.
  $f_{|G}$ est donc injective.\\ Pour conclure montrons que $f(G)$ est fini. Déja $f(G) \subset E^r$ où\\ $E = \{Tr(A), A \in G\}$.
   Il suffit donc de montrer que $E$ est fini, et en effet si $A \in G$, les valeurs propres de $A$ sont des racines de $X^N-1$ qui sont en nombres fini, 
   la trace de $A$ est la somme de ses valeurs propres, donc peut également prendre un nombre fini de valeurs, ainsi $E$ est fini.
}
\exercice{13}{
  Déterminer les endomorphismes de groupe continus de $ (\m{R}^*_+,\times)$.
}{
  Soit $f$ un tel morphisme,
  posons $g = \mathrm{ln}\circ f\circ \mathrm{exp}$. On a \begin{align*}\forall x,y \in \m{R} \quad g(x+y) =&\; \mathrm{ln}(f(e^{x+y})) \\ =&\; 
    \mathrm{ln}(f(e^xe^y)) \\ =&\; \mathrm{ln}(f(e^x)f(e^y))\\ =&\; \mathrm{ln}(f(e^x)) + \mathrm{ln}(f(e^y)) \\ =& \; g(x) + g(y) \end{align*}
    L'application $g$ est continue comme composée, et additive, donc linéaire (c'est un exercice classique), donc il existe $a \in \m{R} $ tel que :
    \begin{align*}\forall x \in \m{R} \quad g(x) &= ax\\ \mathrm{ln}(f(e^x)) &= ax\\ f(e^x) &= e^{ax} \quad \text{par surjectivité de exp } 
      \forall y \in \m{R}  \quad \exists x \in \m{R}^{*}_+ \quad y = e^x \\ \text{donc } \forall y \in \m{R}^{*}_+\quad f(y) &= y^a \end{align*}

    Réciproquement, les fonctions de la forme $x\mapsto x^a$ avec $a \in \m{R}$ sont bien des endomorphismes continus de $(\m{R}^*_+,\times)$.
      \paragraph{Autre Solution :}
      Soit $f$ un tel morphisme, il vérifie : \[\ \forall x,y \in \m{R}^{*}_+ \quad f(xy) = f(x)f(y)\quad\quad  (1) \]
      En particulier $f(1)^2 = f(1)$ donc $f(1) \in \{0,1\}\cap \m{R}^{*}_+ $ donc $f(1) = 1$.
      On va chercher une équation différentielle vérifiée par $f$, pour montrer qu'elle est dérivable, intégrons (1) (bonne idée paradoxale) :
      puisque $f$ est continue et strictement positive : \[\ C := \int^2_1f(y)dy >0  \]
      puis, soit $ x\in \m{R}^{*}_+ $ :  \begin{align*}\int_1^2 f(xy)dy =&\; \int_1^2 f(x)f(y) dy \\
      \int_x^{2 x} f(u) \frac{du}{x} =&\; f(x)\int_1^2 f(y) dy\quad  \text{ avec le changement de variables } u = xy \\
       \text{d'où } f(x) =&\; \frac{1}{xC}\int_x^{2x}f(u) du
      \end{align*}
      $f$ est donc de classe $\mathcal{C}^1$ sur $\m{R}^*_+$.
      On peut donc maintenant dériver (1) par rapport à $x$ :
      \[\ \forall x,y \in \m{R}^*_+ \quad   yf'(xy) = f'(x)f(y) \]
      et en $x=1$ :
       \[\ \forall y \in \m{R}^*_+ \quad yf'(y) = f'(1)f(y) \] 
      En résolvant cette équation différentielle on obtient : \[\ \exists K \in \m{R} \quad \forall x \in \m{R}^*_+ \quad f(x) = Kx^{f'(1)}\]
      puis en évaluant en 1 il vient $K = 1$. Enfin on conclut car toutes les fonctions $x \mapsto x^a$ où $a \in \m{R}$ conviennent.

}
\exercice{14}{
Soit $ R >0 $ et $A$ une partie de la sphère de rayon R, que l'on note $ \\ \mathcal{S}(0,R) =\{z \in \m{C} \;\;|\;\; |z| = R \}$. 
Existe-t-il une série entiere $f:z\mapsto \sum_{n=0}^{\infty}a_nz^n$ de rayon de convergence $R$ tel que l'ensemble des points de $\mathcal{S}(0,R)$ en lesquels $f$ est bien définie (i.e la série converge) soit exactement $A$ ?
}{

On va démontrer que le résultat est faux en général par arguments de cardinalité : \\Soit $R>0$, pour une série entiere $f$ notons $C(f)$ l'ensemble des points de $\mathcal{S}(0,R)$ où $f$ converge. On raisonne par l'absurde en supposant que le résultat est vrai : pour tout  $A \subset \mathcal{S}(0,R)$ il existe une série entiere $f$ de rayon $R$ telle que $C(f) = A$.
On va commencer par démontrer le résultat suivant : 
\paragraph{Lemme :}
Si $(a_n)n$ est une suite de complexes, il existe une suite $(q_n)_n$ de $\m{Q}\left[i\right]$ telle que
 \[\ \forall z \in \m{C}\quad \Bigg(\sum_{n\geq 0}a_nz^n \;\text{ converge } \Leftrightarrow \quad \sum_{n\geq 0} q_nz^n \;\text{ converge}\Bigg)\]
\paragraph{Preuve :}
Soit $(a_n)n \in \m{C}^{\m{N}}$, par densité de $\m{Q}\left[i\right]$ dans $\m{C}$ :
 \[\ \forall n\in \m{N}\quad   \exists q_n \in \mathcal{B}(a_n,\frac{1}{n!})\cap \m{Q}\left[i\right] \] 
 Si on note $\varepsilon_n = q_n-a_n$ alors $\forall n\in \m{N} \quad   q_n = a_n + \varepsilon_n$ et $ |\varepsilon_n| \leq \frac{1}{n!} $,
  donc la série entiere $\sum_{n\geq 0}\varepsilon_nz^n$ a un rayon de convergence infini, de plus : \[\ \forall z \in \m{C} \quad \sum_{n\geq 0} q_nz^n =\sum_{n\geq 0} a_nz^n +\sum_{n\geq 0} \varepsilon_nz^n\] On a donc bien le résultat voulu puisque le terme le plus à droite converge toujours.\; ${\square}$\\
Pour $u = (u_n)_n$ une suite complexe, on note $f_u:z\mapsto \sum_{n = 0}^{\infty}u_nz^n$.
Notre hypothèse implique d'après ce lemme que \[\ \forall A \subset \mathcal{S}(0,R) \quad \exists q \in \m{Q}\left[i\right]^{\m{N}} \text{ tel que }  
f_q \text{ soit de rayon $R$ et } C(f_q) = A \]
 Donc l'application $ \varphi : \left\{\begin{matrix} \m{Q}\left[i\right]^{\m{N}} &\to & \mathcal{P(S(}0,R)) \\ q &\mapsto & C(f_q) \end{matrix} \right. \;\;$
  est surjective. Or on peut montrer avec une bijection de $\m{N}$ dans $\m{Q}$ et l'équipotence de $\m{Q}\left[i\right] $ 
  et $\m{Q}$ que $\m{Q}\left[i\right]^{\m{N}}$ est en bijection avec $\m{N}^{\m{N}}$. De plus $\m{R}$ est en bijection avec 
  $\m{N}^{\m{N}}$, exhibons une surjection, (c'est suffisant pour notre preuve) : à un réel $x$ dont une écriture en base 11 est une suite $(x_n)_n$
   à valeurs dans $\{0,\ldots ,9,A\} $ on associe, si $(x_n)_n$ possède deux $A$ consécutifs ou un nombre fini de $A$, la suite nulle et sinon la suite 
   $(a_n)_n$ definit par : $\forall n \in \m{N}\quad a_n $ est l'entier dont l'écriture décimale est $x_{i_n +1} \ldots x_{i_{n+1}-1}$ où $i_n$ désigne le rang du $n$-ième A dans $(x_n)_n $. Cette application est facilement surjective, par composition, on dispose donc d'une surjection de $\m{R}$ dans $\mathcal{P(S}(0,R))$. Or $\psi :\left\{\begin{matrix} \left[0,1\right[ & \to & \mathcal{S}(0,R) \\ t &\mapsto & Re^{2i\pi t}\end{matrix}\right. $ est bijective et donc démontre, connaissant l'équipotence de $\left[0,1\right[$ et $\m{R}$, que $S(0,R)$ est en bijection avec $\m{R}$, il vient ensuite que $\mathcal{P(S}(0,R))$ est en bijection avec $\mathcal{P}(\m{R})$. On a donc grace à tout ce qui précède, une surjection de $\m{R}$ dans $\mathcal{P}(\m{R})$ ce qui est absurde d'après le théorème de Cantor.

}
%------------------------------------------------------------------------------------------------------------------------------------------------
%------------------------------------------------------------------------------------------------------------------------------------------------

\exercice{15 (D'après \cite{ulm2019})}{ $\\$

Calculer  \[\ \lim_{x\to\infty}\Biggl( \sum_{n=1}^{\infty} \Bigl(\frac{x}{n}\Bigr)^n\Biggr)^{\frac{1}{x}} \]
}{
Le $n^{-n}$ peut nous rappeler la fameuse et magnifique identité : 
\[\ \int_0^1 t^{-t}\,\mathrm{d}t = \sum_{n=1}^\infty n^{-n} \]
Baptisée ``Sophomore's dream'' ou ``rêve du deuxième année'' ( oui oui, elle est vraie !!)

On va enfait montrer qu'on a même : \[\ \forall x \in \mathbb{R} \quad \int_0^1 t^{-xt}\,\mathrm{d}t = \sum_{n=1}^\infty x^{n-1}n^{-n} \]
Pour $x=0 $ l'intégrale converge, pour $x\neq0$  $t^{-xt} = e^{-xt\ln(t)} \to 1 $ car $t\ln(t) \to 0$ quand $t \to 0$, l'intégrale converge également. Pour la série entière, son rayon de convergence est clairement infini.
Soit  $x \in \mathbb{R}$:
\begin{align*} \int_0^1 t^{-xt}\,\mathrm{d}t  &= \int_0^1 e^{-xt\ln(t)} \mathrm{d}t \\ & = \int_0^1\sum_{n=0}^{\infty}\frac{(-xt\ln(t))^n}{n!} \mathrm{d}t  \\  ^{(*)} &= \sum_{n=0}^{\infty}\int_0^1\frac{(-xt\ln(t))^n}{n!} \mathrm{d}t  \\ & = \sum_{n=0}^{\infty}\int_{+\infty}^0\frac{(-1)^nx^ne^{\frac{-un}{n+1}}(-u)^n}{n!(n+1)^n} \Bigl(\frac{-e^{-\frac{u}{n+1}}}{n+1}\Bigr)\mathrm{d}u \quad \text{ avec } t=e^{-\frac{u}{n+1}} 
\\ & = 
\sum_{n=0}^{\infty}\frac{x^n}{n!(n+1)^{n+1}}\int_0^{+\infty} e^{-u}u^n\mathrm{d}u 
\\ & = 
\sum_{n=0}^{\infty}\frac{x^n}{n!(n+1)^{n+1}}\Gamma(n+1)
\\ & = \sum_{n=0}^{\infty}\frac{x^n}{(n+1)^{n+1}}
\\ & = \sum_{n=1}^{\infty}x^{n-1}n^{-n}
\end{align*}
(*) Notons $f_n(t) = \frac{(-xt\ln(t))^n}{n!}$, $\forall n \in \mathbb{N} \quad f_n$ est cpm et intégrable sur [0,1], de plus $\sum f_n$ converge simplement vers $F_x:t\mapsto t^{-xt}$ qui est cpm. Enfin comme $t \in [0,1] \;\; f_n$ est de signe constant, notre calcul à partir de (*) justife donc la convergence de $\sum\int_0^1|f_n|$. L'échange série - intégrale est donc justifié.
Alors \[\ S(x) := \Biggl( \sum_{n=1}^{\infty} \Bigl(\frac{x}{n}\Bigr)^n\Biggr)^{\frac{1}{x}} = \;\; x^{\frac{1}{x}}\Biggl(\int_0^1 t^{-xt} \mathrm{d}t\Biggr)^{\frac{1}{x}} \] D'abord, $x^{\frac{1}{x}} = e^{\frac{\ln(x)}{x}} \to 1$ Puis pour $x \geq 1$ : \[\ \Biggl(\int_0^1 t^{-xt} \mathrm{d}t\Biggr)^{\frac{1}{x}}  = \Biggl(\int_0^1 (t^{-t})^x \mathrm{d}t\Biggr)^{\frac{1}{x}} = \|f\|_{_x} \] Où $f: t \mapsto t^{-t}$. On se rappelle alors de l'exercice affirmant que \[\ \|f\|_{_x} \xrightarrow[x \to \infty]{} \|f\|_{_\infty} = \sup_{t\in [0,1]}|f(t)| \] Avec une rapide étude de $f$ on trouve que sa borne sup vaut $e^{\frac{1}{e}}$. Ainsi, \[\ \lim_{x \to \infty}S(x) = e^{\frac{1}{e}}\quad _{_\square} \] 
}

\exercice{16 (D'après \cite{igor})}{

Soit (E,d) un espace métrique
 compact et \begin{math} 
f: E\rightarrow  E  
\end{math} continue  
telle que : \\ 
\[\
\forall x,y \in E\;\;\; d(f(x),f(y)) \geq d(x,y) \;\;\;\;\;\;(*)
\]\
Démontrer que f est bijective puis que f est une isométrie.
}{
Soient\(\ x,y \in E \)\ tels que \(\ 
f(x) = f(y) \)\ alors $ 0 = d(f(x),f(y)) \geq d(x,y) \geq 0 $
donc $x= y $, ainsi $f$ est injective.\\
Pour la surjectivité fixons $y\in E$ et remarquons que pour $x\in E$ et $n\in \mathbb{N}$ \[\
d(f^{n+1}(x),f^{n}(y)) \geq d(f(x),y)
\]\ On cherche donc $x$ tel que $d(f^{n+1}(x),f^{n}(y)) \rightarrow 0$.
Comme $E$ est compact on peut trouver  une extractrice $\phi$ et $l\in E$ telle que : \[\ f^{\phi(n)}(y)\rightarrow l
\]\  Posons $x_n = f^{\phi(n+1)-\phi(n)-1}(y)$ et $a_n = f^{\phi(n)+1}(x_n)$
 Alors 
\[\ a_n = 
f^{\phi(n)+1}(f^{\phi(n+1)-\phi(n)-1}(y)) = f^{\phi(n+1)}(y) \rightarrow l
\]\ 
Extrayons une deuxième fois : il existe une extractrice $\psi$ et $x \in E$ tels que : 
\[\ x_{\psi(n)} \rightarrow x
\]\ Comme 
\[\ f^{\phi(\psi(n))+1}(x_{\psi(n)}) \rightarrow l,  \]\ (c'est une suite extraite de $a_n$), on aimerait en conclure que : 
\[\ f^{\phi(\psi(n))+1}(x) \rightarrow l
\]\ Attention ici à ne pas essayer d'utiliser la continuité de $f^{\phi(\psi(n))+1}$ , la dépendance en $n$ nous en empèche.
Nous allons pour cela montrer le résultat suivant : 
\paragraph{Lemme}
Soient $u_n \in \mathbb{N}^{\mathbb{N}}$ tendant vers $+\infty$, $b_n \in E^{\mathbb{N}} $ tendant vers $b \in E$ et $l,l'$  dans $E$ tels que : 
\[\ f^{u_n}(b_n) \rightarrow l \;\;\;et\;\;\;  f^{u_n}(b) \rightarrow l' \] Alors $l = l'$
\paragraph{Preuve}
Soit $\epsilon > 0$ : \[\ 
   \forall k,n\in \mathbb{N} \;\;\; d(f^{u_n}(b),l) \leq d(f^{u_n}(b),l') + d(l',f^{u_k}(b))  + d(f^{u_k}(b),f^{u_k}(b_n))+d(f^{u_k}(b_n),l) \;\;\;\;(1)\]\ De plus, en appliquant (*), si $u_n \geq u_k$:  
\[\  d(f^{u_k}(b_n),l) \leq d(f^{u_n}(b_n),f^{u_n-u_k}(l)) \leq d(f^{u_n}(b_n),l) + d(l,f^{u_n-u_k}(l))  \leq d(f^{u_n}(b_n),l) + d(f^{u_k}(l),f^{u_n}(l)) \]\
Par compacité, on dispose d'une extractrice $\phi$ et de $l_1 \in E$ telle que $f^{u_{\phi(p)}}(l)  \rightarrow l_1 \\ $
Finalement, en injectant dans (1) : \[\ d(f^{u_n}(b),l) \leq d(f^{u_n}(b),l') + d(l',f^{u_k}(b))  + d(f^{u_k}(b),f^{u_k}(b_n))+ d(f^{u_n}(b_n),l) + d(f^{u_k}(l),l_1) + d(l_1,f^{u_n}(l)) \]\
On peut donc  trouver $N_1 \in \mathbb{N} $ tel que $\forall p \geq N_1 \;\;\;d(f^{u_{\phi(p)}}(l),l_1) \leq \epsilon $ Il existe aussi $N_2 \in \mathbb{N} $ tel que $\forall p \geq N_2 \;\;\;d(l',f^{u_p}(b)) \leq \epsilon$. Fixons donc $ p_1 \geq max(N1,N2) $ et posons $ k = \phi(p_1) $ Ainsi $k \geq p_1 \geq N_2 $ et $k\geq N_1$ Donc \[\ \forall n \in \mathbb{N}\;\;\; d(f^{u_n}(b),l) \leq 2\epsilon + d(f^{u_n}(b),l')   + d(f^{u_k}(b),f^{u_k}(b_n))+ d(f^{u_n}(b_n),l) +  d(l_1,f^{u_n}(l)) \]\ Maintenant que k est fixé, on peut utiliser la continuité de $f^{u_k} \; : \;\\ \exists N_3 \in \mathbb{N} \;\;\; \forall p \geq N_3\;\;\; d(f^{u_k}(b),f^{u_k}(b_n)) \leq \epsilon \;\;\;\;\;\;  $ ($N_3$ dépend de k)$
\\ \exists N_4 \in \mathbb{N} \;\;\; \forall p \geq N_4\;\;\; d(f^{u_p}(b_p),l) \leq \epsilon \\ \\$ Soit donc $p_2 \geq max(N_1,N_2,N_3,N_4)$ et $n := \phi(p_2)  $ vérifiant $u_n \geq u_k \;\;\;\; $ (possible car $u$ tends vers $+\infty) \\ $ donc $ n \geq max(N_1,N_2,N_3,N_4) \\ $ On peut conclure : \[\  d(f^{u_n}(b),l) \leq 6\epsilon\]\ Ainsi $l$ est une valeur d'adhérence de $(f^{u_n}(b))_n$ et comme elle converge vers $l'$ on a bien $l=l'$ $_\Box \\ \\$

Pour utiliser notre lemme, on a donc besoin que $f^{\phi(\psi(n))+1}(x)$ converge,
 ce n'est pas forcément le cas, extrayons : il existe $ \gamma $ une extractrice
  et $l' \in E$ tels que \[\ f^{\phi(\psi(\gamma(n)))+1}(x) \rightarrow l' \]\ 
  Notons $u_n = \phi(\psi(\gamma(n)))$. On a : \[\ f^{u_n+1}(x_{\psi(\gamma(n))})
   \rightarrow l \;\;\;\; et \;\;\;\; x_{\psi(\gamma(n))} \rightarrow x\]\ Donc par
    le lemme : \[\ f^{u_n+1}(x) \rightarrow l \]\ On obtient donc
     \[\ d(f^{u_n + 1}(x),f^{u_n}(y)) \geq d(f(x),y) \] En passant 
     a la limite : \[\ d(f(x),y) \leq d(l,l) = 0 \] Ainsi $f(x) = y $, 
     ce qui démontre la surjectivité de $f$.  \[\ \]

Démontrons maintenant que $f$ est une isométrie : $\\ $ Comme $f$ est bijective on peut maintenant écrire : \[\ \forall x,y \in E \;\; d(x,y) \geq d(f^{-1}(x),f^{-1}(y))\;\;\;\;\;\;\;\; (**) \]
Pour $x,y \in E$ posons $\forall n \in \mathbb{N} \;\; d_n = d(f^{-n}(x),f^{-n}(y))$. D'après (**), $ (d_n)$ est décroissante, de plus elle est minorée par 0, elle est donc convergente, notons $l$ sa limite. Comme $E$ est compact il existe $\gamma , \psi $ des extractrices et $a,b\in E$ tels que \[\
f^{-\gamma(n)}(x) \rightarrow a, \;\;\; f^{-\gamma(\psi(n))}(y) \rightarrow b
\] Notons $\phi = \gamma \circ \psi$. Alors comme $d_{\phi(n)} \rightarrow l $ on a : $d(a,b) = l$, de plus par continuité de $f$ : \[\ f^{-\phi(n) + 1}(x) \rightarrow f(a), \;\;\; f^{-\phi(n) + 1}(y) \rightarrow f(b) \] Donc \[\ d(f^{-\phi(n) + 1}(x),f^{-\phi(n) + 1}(y)) \rightarrow d(f(a),f(b)) \]
Mais $d_{\phi(n) - 1}$ tends aussi vers $l$ donc  \[\ d(f(a),f(b)) = d(a,b) = l\] Ce qui ressemble pas mal a ce q'on cherche, on le veut pour tout $a,b \in E $. Fixons donc $a,b \in E$. Il suffirait donc d' avoir l' existence de $ x,y\in E$ ainsi que de $\gamma$ et $\psi$ des extractrices telles que \[\
f^{-\gamma(n)}(x) \rightarrow a, \;\;\; f^{-\gamma(\psi(n))}(y) \rightarrow b
\] Commençons avec $a$, ce n'est pas évident... On peut essayer d'exprimer $x$ en fonction de $a$ et naivement écrire ``$ x = f^{\gamma(n)}(a)"$ ce qui n'a pas de sens, mais $(f^{n}(a))_n$ est bien une suite de $E$ dont on peut donc extraire une suite convergente notons justement, pour voir $\gamma$ l'extractrice et  $x$ la limite :  \[\ f^{\gamma(n)}(a) \rightarrow x \] Notons $x_n = f^{\gamma(n)}(a)$. Alors comme $f^{-\gamma(n)}(x_n) = a$ on a : \[\ f^{-\gamma(n)}(x_n) \rightarrow a \;\;\; et \;\;\; x_n \rightarrow x\] Cela nous rappelle notre lemme, il nous manque l'hypothèse : ``$f^{-\gamma(n)}(x)$ converge '', mais quitte a extraire et a remplacer $\gamma$ par $\gamma \circ \gamma'$ par exemple, on peut la supposer vraie. Autre problème : la suite $(-\gamma(n))_n $ ne tends pas vers $+\infty \\ \\$
  Adaptons notre lemme aux suites de $\mathbb{Z}^{\mathbb{N}}$ qui tendent vers $-\infty$. En regardant la preuve on voit que l'hypothèse ``$u_n \in \mathbb{N}^{\mathbb{N}}$ '' n'est utilisé que pour avoir la continuité de $f^{u_k}$ car $f^{-1}$ n'est a priori pas continue, sauf qu'en fait si car elle est directement 1-lipschitzienne par (**) on peut donc prendre $u \in \mathbb{Z}^{\mathbb{N}}$. L'hypothèse ``$u_n \rightarrow +\infty$'' par contre  est nécessaire pour trouver $n$ vérifiant $u_n \geq u_k$ et appliquer la majoration $d(f^{u_k}(b_n),l) \leq d(f^{u_n}(b_n),f^{u_n-u_k}(l))$. Bon... reprenons les mêmes notations et changeons la première ligne en : \[\ 
   \forall n\in \mathbb{N} \;\;\; d(f^{u_n}(b),l) \leq d(f^{u_n}(b),f^{u_n}(b_n))+d(f^{u_n}(b_n),l) \;\;\;\;\]\ Dès que $u_n$ est négative, $d(f^{u_n}(b),f^{u_n}(b_n)) \leq d(b,b_n)$ en itérant (**). Mais comme $b_n \rightarrow b$ et $f^{u_n}(b_n) \rightarrow l$ on a directement $f^{u_n}(b) \rightarrow l$ puis $l = l'$. Donc c'est bon, c'était plus simple comme ça !  $ \\ \\ $ On peut donc utiliser cette version du  lemme et conclure que $f^{-\gamma(n)}(x)
   \rightarrow a $.
   Tout se passe exactement pareil pour trouver $y$ et $\psi$ si  on commence par extraire de la suite $(f^{\gamma(n)}(b))_n$. Cela conclut la preuve.
}

\exercice{17 (Preuve topologique de Cayley-Hamilton)}{

Soit $A\in \mn{C}$,\\
1) Démontrer que si $A$ est diagonalisable, alors $\chi_{_A}(A) =0$.\\
2) En déduire que $\chi_{_A}(A)=0$.
}
{
1) On note $A= PDP^{-1}$ où $D$ est diagonale, P inversible.
On a facimement $\chi_{_A}(A) = \chi_{_D}(A) = \chi_{_D}(D)$. 
Mais cette matrice est diagonale, et s'écrit $\prod_{i=1}^n(D-\lambda_i I_n)$. Où $Sp(A) = \{ \lambda _1,\ldots ,\lambda _n\}$. Et comme les coefficients diagonaux de $D$ sont aussi les valeurs propres de $A$, on peut voir que ce produit de matrices diagonales est nul.\\
2) On va conclure par densité des matrices diagonalisables dans $\mn{C}$ : on dispose d'une suite $(A_n)_n$ de matrices diagonalisables qui tends vers $A$. Cela ne dépend pas des normes, en dimension finie. Il suffit d'après 1) de montrer que $\chi_{_{A_n}}(A_n) \to \car{A}(A)$ car il s'agirait alors de la limite de la suite nulle.
L'application $f:M \mapsto \car{M}$ est continue puisque $ \car{M} = \mathrm{det}(XI_n-M)$ et le déterminant est polynomial en les coefficients de la matrice. Choisissons des normes qui nous arrangent : la norme infinie sur $\mn{C}$, on note $B = \mathcal{B}_f(A,1)$ et on pose pour $P\in \m{C}_n\left[X\right] \quad \|P\| := \mathrm{sup}_{M\in B}\|P(M)\|_{\infty}$. Le sup est bien définit car $P$ est continue sur le compact $B$ donc majorée. Montrons qu'on définit ainsi une norme : \\ 
Soient $P,Q \in \m{C}_n\left[X\right],\; \lambda \in \m{C}, $\\
$\bullet $ Homgénéité : $\|\lambda P\| = \mathrm{sup}_{M\in B}\|\lambda P(M)\|_{\infty}= \mathrm{sup}_{M\in B}|\lambda| \| P(M)\|_{\infty}= |\lambda|\n{P}$.\\
$\bullet$ Inégalité triangulaire :
$\forall M\in B \quad \n{P(M)+Q(M)}_{\infty}\leq \n{P(M)}_{\infty}+\n{Q(M)}_{\infty} \leq \n{P} + \n{Q} $ par passage au sup : $\n{P+Q}\leq \n{P} +\n{Q} $.\\
$\bullet$ Definition : Supposons $\n{P} =0$, $P$ est donc nul sur $B$. Par densité de $\gln{C}$ dans $\mn{C}$, on peut trouver $U \in \gln{C} \cap \mathring{B} $. Soit $\lambda$ une valeur propre de $U$ (il en existe toujours car son polynome caractéristique est scindé sur $\m{C}$) et $X$ un vecteur propre associé, comme $U$ est inversible, nécéssairement $\lambda \neq 0$. Puisque $\mathring{B}$ est ouvert, il existe $\varepsilon >0 $ tel que $\mathcal{B}(U,\varepsilon)\subset \mathring{B}$ En particulier $\forall t\in \left[0,\varepsilon \right[ \quad P(tU) = 0$. Puis pour $t\in \left[0,\varepsilon \right[ $ : \begin{align*}
tUX &= t\lambda X\\
P(tU)X &= P(t\lambda)X = 0
\end{align*}
Or $X \neq 0$ donc $P(t\lambda) =0$, $\lambda$ étant non nul, $P$ admet une infinité de racines dans $\m{C}$, donc $P=0$. (Remarquons que cela définit même une norme sur $\m{C}\left[X\right] $.)\\
\\
Puisque $f$ est continue on a $\car{A_n} \to \car{A}$ pour $\n{.}$ i.e $\n{\car{A_n}-\car{A}} \to 0$ i.e la suite de fonctions $(\car{A_n})_n$ converge uniformément vers $\car{A}$ sur $B$. Donc pour $n$ suffisament grand, $A_n\in B $ et \begin{align*}\n{\car{A_n}(A_n)-\car{A}(A)}_{\infty} &\leq \n{\car{A_n}(A_n)-\car{A}(A_n)}_{\infty} + \n{\car{A}(A_n)-\car{A}(A)}_{\infty}\\ &\leq \n{\car{A_n}-\car{A}} + \n{\car{A}(A_n)-\car{A}(A)}_{\infty} \end{align*}
On a vu que le terme de gauche tend vers 0, celui de droite tend aussi vers 0 par continuité de $M\mapsto \car{A}(M)$ comme polynome.
On a bien $\car{A_n}(A_n) \to \car{A}(A)$. 
}
\exercice{18 (D'après \cite{ulm2019})}{
Soit $f: \m{R}_+ \to \m{R}_+$ continue et telle que $I:= \int_0^{+\infty}f^2(x)dx < \infty$.\\
Déterminier \[ \lim_{x\to +\infty } \frac{\int_0^xe^tf(t)dt}{e^x}\]
}
{
Il faut ici reconaitre la solution d'une équation différentielle de la forme : \[ y' + y = f \quad\quad\quad (1)\] Si on pose : \[\forall x \in \m{R}_+ \quad y(x) = e^{-x}\int_0^xe^tf(t)dt \] alors $y$ est clairement solution de  (1). Faisons maintenant aparaître $I$ : \begin{align*}
y'+y &= f \\
(y'+y)^2 &= f^2\\ 
y'^2 + 2yy' + y^2 &= f^2 \\
\text{En intégrant : } \int_0y'^2 + \int_02yy' +\int_0y^2 &= \int_0 f^2\\
\int_0y'^2 + y^2-y(0)^2 + \int_0 y^2 &= \int_0f^2 \quad\quad (2)\\ \text{puis } \int_0 y^2 &\leq \int_0 y'^2 + y^2 + \int_0 y^2\\
&\leq y(0)^2 + \int_0 f^2\\ &\leq y(0)^2 +I
\end{align*}
La fonction $\int_0y^2$ étant croissante car de dérivée $y^2 \geq 0$ et majorée, elle admet un limite en $+\infty$. Il en est de même pour $\int_0y'^2$, on voit donc avec (2) que $y^2$
 converge également en $+\infty$, notons $l$ sa limite puisque $\int_0^{+\infty}y^2$ est convergente, nécéssairement $l=0$. Donc \[ \lim_{x\to+\infty}y(x) =0\].
}

\exercice{19}{
Soit $f : \m{R} \longrightarrow \mn{R}$ dérivable, montrer que :
\[ \tx{det}(f)' = \tx{Tr(Com}(f)^Tf')
\] de deux manières différentes.
}{
Première méthode. Notons $f_{i,j}$ les applications coordonnés de $f$ dans la base cannonique.
\begin{align*}
\tx{Tr(Com}(f)^Tf') &= \sum_{i=1}^n \left[\tx{Com(}f)^T f'\right]_{i,i} \\
&= \sum_{i=1}^n \sum_{k=1}^n \left[\tx{Com}(f)^T\right]_{i,k}f'_{k,i} \\ &=\sum_{i=1}^n \sum_{k=1}^n (-1)^{i+k}\Delta_{k,i}f'_{k,i}\\
\end{align*}
Pause, calculons $\Delta_{k,i}$ pour $1\leq i,k\leq n$, en notant $\tilde{f}$ la fonction à valeurs dans $\mathcal{M}_{n-1}(\m{R})$ déduite de $f$ en retirant la k-ème ligne et la i-ème colone : \\
\begin{align*}
\Delta_{k,i} &= \tx{det}(\tilde{f})\\
&= \sum_{\sigma \in S_{n-1}}\varepsilon(\sigma)\prod_{j=1}^{n-1}\tilde{f}_{\sigma(j),j} \\
&= \sum_{\sigma \in S_{n-1}}\prod_{l<m}\Bigl(\frac{\sigma(l)-\sigma(m)}{l-m}\Bigr)\prod_{j=1}^{n-1}\tilde{f}_{\sigma(j),j} \\
&= \sum_{\sigma \in S_n,\sigma(i)=k}\prod_{l<m,l,m \neq i } \Bigl(\frac{\sigma(l)-\sigma(m)}{l-m}\Bigr)\prod_{j =1, j\neq i}^{n}f_{\sigma(j),j}
\\&= \sum_{\sigma \in S_n,\sigma(i)=k}\varepsilon(\sigma)\prod_{l\neq i }^n\Bigl(\frac{\sigma(l)-\sigma(i)}{l-i}\Bigr)^{-1}
\prod_{j =1, j\neq i}^{n}f_{\sigma(j),j}
\\&= \sum_{\sigma \in S_n,\sigma(i)=k}\varepsilon(\sigma)\prod_{l\neq i }^n\Bigl(\frac{l-i}{\sigma(l)-k}\Bigr)
\prod_{j =1, j\neq i}^{n}f_{\sigma(j),j}\end{align*} La valeur absolue de ce premier produit vaut 1 et il contient $i-1$ numérateurs négatifs et $k-1$ dénominateurs négatifs, il vaut donc $(-1)^{i-1 + k-1} = (-1)^{i+k}$. Reprenons le calcul : 
\begin{align*}
\tx{Tr(Com}(f)^Tf') &= 
\sum_{i=1}^n \sum_{k=1}^n (-1)^{i+k}\Delta_{k,i}f'_{k,i} \\
&= \sum_{i=1}^n \sum_{k=1}^n (-1)^{2i+2k}\sum_{\sigma \in S_n,\sigma(i)=k}\varepsilon(\sigma)
\prod_{j =1, j\neq i}^{n}f_{\sigma(j),j}f'_{k,i}
\\&= \sum_{i=1}^n\sum_{\sigma \in S_n}\varepsilon(\sigma)
\prod_{j =1, j\neq i}^{n}f_{\sigma(j),j}f'_{\sigma(i),i}
\\
&= \sum_{\sigma \in S_n}\sum_{i=1}^n\varepsilon(\sigma)
\prod_{j =1, j\neq i}^{n}f_{\sigma(j),j}f'_{\sigma(i),i}
\\&= \sum_{\sigma \in S_n}\varepsilon(\sigma)
\Biggl(\prod_{j =1}^{n}f_{\sigma(j),j}\Biggr)'
\\
&= \tx{det}(f)'
\end{align*}
Deuxième méthode. On va calculer la différentielle du determinant : 

Soit $M \in \mn{R}$, on note $\nabla M$ le gradient du determinant en $M$ et $(e_{i,j})_{1\leq i, j \leq n}$ la base canonique. 
Avec la formule de dérivation des formes $n$-linéaires et en notant $C_i$ la fonction "colone $i$" sur $\mn{R}$:\begin{align*} \left[\nabla M\right]_{i,j} = \frac{\partial \tx{det}}{\partial e_{i,j}}(M) =& \sum_{k=1}^n \tx{det}(C_1,\ldots,\frac{\partial C_k}{\partial e_{i,j}},\ldots,C_n)(M)\\
 =& \;\tx{det}(C_1,\ldots,\frac{\partial C_j}{\partial e_{i,j}},\ldots,C_n)(M)\\
 =& \begin{vmatrix}m_{1,1}& \ldots& 0&\ldots& m_{1,n}& \\ \vdots & \ddots & \vdots & \ddots &\vdots \\m_{i,1}& \ldots& 1& \ldots& m_{i,n}&\\ \vdots & \ddots & \vdots & \ddots &\vdots \\ m_{n,1}& \ldots& 0&\ldots & m_{n,n}& \end{vmatrix} \end{align*}
En développant suivant la $j$-ème colone il vient $\left[\nabla M\right]_{i,j} = (-1)^{i+j} \Delta_{i,j}$ puis $\nabla M = \tx{Com}(M)$. Notons $D_M$ la différentielle du det en $M$, alors : \[ \forall H \in \mn{R}\quad D_M(H) = <\nabla M,H> = \tx{Tr(Com}(M)^TH) \]
Puis, $\forall x \in \m{R} \quad \tx{det}(f)'(x) = d(\tx{det}\circ f)_x(1) = D_{f(x)}\circ\; df_x(1) = \tx{Tr(Com}(f(x))^Tf'(x))$
 }

\printbibliography %Prints bibliography

\end{document} 